{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a keyword: geeks for geeks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv \n",
    "import pickle\n",
    "import google.oauth2.credentials\n",
    " \n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    " \n",
    "# The CLIENT_SECRETS_FILE variable specifies the name of a file that contains\n",
    "# the OAuth 2.0 information for this application, including its client_id and\n",
    "# client_secret.\n",
    "CLIENT_SECRETS_FILE = \"client_secret.json\"\n",
    " \n",
    "# This OAuth 2.0 access scope allows for full read/write access to the\n",
    "# authenticated user's account and requires requests to use an SSL connection.\n",
    "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
    "API_SERVICE_NAME = 'youtube'\n",
    "API_VERSION = 'v3'\n",
    " \n",
    " \n",
    "def get_authenticated_service():\n",
    "    credentials = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            credentials = pickle.load(token)\n",
    "    #  Check if the credentials are invalid or do not exist\n",
    "    if not credentials or not credentials.valid:\n",
    "        # Check if the credentials have expired\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                CLIENT_SECRETS_FILE, SCOPES)\n",
    "            credentials = flow.run_console()\n",
    " \n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    " \n",
    "    return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)\n",
    " \n",
    " \n",
    "def get_video_comments(service, **kwargs):\n",
    "    comments = []\n",
    "    results = service.commentThreads().list(**kwargs).execute()\n",
    " \n",
    "    while results:\n",
    "        for item in results['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    " \n",
    "        # Check if another page exists\n",
    "        if 'nextPageToken' in results:\n",
    "            kwargs['pageToken'] = results['nextPageToken']\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    return comments\n",
    " \n",
    " \n",
    "def write_to_csv(comments):\n",
    "    with open('comments.csv', 'w' , encoding=\"utf-8\") as comments_file:\n",
    "        comments_writer = csv.writer(comments_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        comments_writer.writerow(['Video ID', 'Title', 'Comment'])\n",
    "        for row in comments:\n",
    "            # convert the tuple to a list and write to the output file\n",
    "            comments_writer.writerow(list(row))\n",
    " \n",
    " \n",
    "def get_videos(service, **kwargs):\n",
    "    final_results = []\n",
    "    results = service.search().list(**kwargs).execute()\n",
    " \n",
    "    i = 0\n",
    "    max_pages = 3\n",
    "    while results and i < max_pages:\n",
    "        final_results.extend(results['items'])\n",
    " \n",
    "        # Check if another page exists\n",
    "        if 'nextPageToken' in results:\n",
    "            kwargs['pageToken'] = results['nextPageToken']\n",
    "            results = service.search().list(**kwargs).execute()\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    return final_results\n",
    " \n",
    " \n",
    "def search_videos_by_keyword(service, **kwargs):\n",
    "    results = get_videos(service, **kwargs)\n",
    "    final_result = []\n",
    "    for item in results:\n",
    "        title = item['snippet']['title']\n",
    "        video_id = item['id']['videoId']\n",
    "        comments = get_video_comments(service, part='snippet', videoId=video_id, textFormat='plainText')\n",
    "        # make a tuple consisting of the video id, title, comment and add the result to \n",
    "        # the final list\n",
    "        final_result.extend([(video_id, title, comment) for comment in comments]) \n",
    " \n",
    "    write_to_csv(final_result)\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # When running locally, disable OAuthlib's HTTPs verification. When\n",
    "    # running in production *do not* leave this option enabled.\n",
    "    os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "    service = get_authenticated_service()\n",
    "    keyword = input('Enter a keyword: ')\n",
    "    search_videos_by_keyword(service, q=keyword, part='id,snippet', eventType='completed', type='video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k4286q_Tovc</td>\n",
       "      <td>Webinar | How to Begin with Competitive Progra...</td>\n",
       "      <td>He looks like a bit of younger version of Abhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k4286q_Tovc</td>\n",
       "      <td>Webinar | How to Begin with Competitive Progra...</td>\n",
       "      <td>Hey can u tell us the name of the dsa course t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k4286q_Tovc</td>\n",
       "      <td>Webinar | How to Begin with Competitive Progra...</td>\n",
       "      <td>sir I am currently doing cp on hackerrank how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k4286q_Tovc</td>\n",
       "      <td>Webinar | How to Begin with Competitive Progra...</td>\n",
       "      <td>ðŸ¤”ðŸ¤¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k4286q_Tovc</td>\n",
       "      <td>Webinar | How to Begin with Competitive Progra...</td>\n",
       "      <td>what is his name?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID                                              Title  \\\n",
       "0  k4286q_Tovc  Webinar | How to Begin with Competitive Progra...   \n",
       "1  k4286q_Tovc  Webinar | How to Begin with Competitive Progra...   \n",
       "2  k4286q_Tovc  Webinar | How to Begin with Competitive Progra...   \n",
       "3  k4286q_Tovc  Webinar | How to Begin with Competitive Progra...   \n",
       "4  k4286q_Tovc  Webinar | How to Begin with Competitive Progra...   \n",
       "\n",
       "                                             Comment  \n",
       "0  He looks like a bit of younger version of Abhi...  \n",
       "1  Hey can u tell us the name of the dsa course t...  \n",
       "2  sir I am currently doing cp on hackerrank how ...  \n",
       "3                                                 ðŸ¤”ðŸ¤¨  \n",
       "4                                  what is his name?  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"comments.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sir',\n",
       " 'I',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'doing',\n",
       " 'cp',\n",
       " 'on',\n",
       " 'hackerrank',\n",
       " 'how',\n",
       " 'much',\n",
       " 'time',\n",
       " 'shall',\n",
       " 'i',\n",
       " 'devote',\n",
       " 'to',\n",
       " 'it']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('all')\n",
    "word_tokens=nltk.word_tokenize(data[\"Comment\"][2])\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sir', 'I', 'currently', 'cp', 'hackerrank', 'much', 'time', 'shall', 'devote']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalWords</th>\n",
       "      <th>StemmedWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hackerrank</td>\n",
       "      <td>hackerrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shall</td>\n",
       "      <td>shall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>devote</td>\n",
       "      <td>devot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OriginalWords StemmedWords\n",
       "0           sir          sir\n",
       "1             I            I\n",
       "2     currently      current\n",
       "3            cp           cp\n",
       "4    hackerrank   hackerrank\n",
       "5          much         much\n",
       "6          time         time\n",
       "7         shall        shall\n",
       "8        devote        devot"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer= PorterStemmer()\n",
    "# words  = nltk.word_tokenize(data[\"Comment\"][4])\n",
    "df = pd.DataFrame()\n",
    "df['OriginalWords'] = pd.Series(filtered_sentence)\n",
    "StemmedWords = [stemmer.stem(word) for word in filtered_sentence]\n",
    "df['StemmedWords'] = pd.Series(StemmedWords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalWords</th>\n",
       "      <th>StemmedWords</th>\n",
       "      <th>Lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently</td>\n",
       "      <td>current</td>\n",
       "      <td>currently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp</td>\n",
       "      <td>cp</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hackerrank</td>\n",
       "      <td>hackerrank</td>\n",
       "      <td>hackerrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shall</td>\n",
       "      <td>shall</td>\n",
       "      <td>shall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>devote</td>\n",
       "      <td>devot</td>\n",
       "      <td>devote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OriginalWords StemmedWords  Lemmatizer\n",
       "0           sir          sir         sir\n",
       "1             I            I           I\n",
       "2     currently      current   currently\n",
       "3            cp           cp          cp\n",
       "4    hackerrank   hackerrank  hackerrank\n",
       "5          much         much        much\n",
       "6          time         time        time\n",
       "7         shall        shall       shall\n",
       "8        devote        devot      devote"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "LemmatizedWords = [lemmatizer.lemmatize(word) for word in filtered_sentence]\n",
    "df['Lemmatizer'] = pd.Series(LemmatizedWords)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
